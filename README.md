# ğŸ“Š Day 07 : Regression Analysis

A comprehensive guide to three regression implementations using Python, scikit-learn, and scipy.

---

## ğŸ“š Three Implementation Files

### 1ï¸âƒ£ **Regression.ipynb** - Simple Linear Regression (scipy)

#### ğŸ¯ What it does:

Basic linear regression using scipy's `stats.linregress()` - **No train/test split**

#### ğŸ”‘ Key Steps:

```
ğŸ“¥ Input: x and y arrays (hardcoded values)
     â†“
ğŸ“ˆ Calculate: slope, intercept using scipy.stats
     â†“
ğŸ¨ Plot: Scatter plot + line of best fit
     â†“
ğŸ“Š Output: Correlation coefficient (r value)
```

#### ğŸ’¡ Quick Memory:

- **Quick & Simple** âœ¨
- Uses scipy, not sklearn
- Perfect for understanding basic concept
- Shows regression line visually

#### ğŸ”¢ Key Variables:

- `x`, `y` â†’ Input data
- `slope`, `intercept`, `r` â†’ Regression parameters
- `mymodel` â†’ Predicted y values

---

### 2ï¸âƒ£ **RegressionEX.ipynb** - Simple Linear Regression (sklearn)

#### ğŸ¯ What it does:

Linear regression with **single feature (TV)** using sklearn with train/test split

#### ğŸ”‘ Key Steps:

```
ğŸ“¥ Load Data: Advertising.csv
     â†“
ğŸ” Select Features: Keep only 'TV' column (drop radio, newspaper)
     â†“
ğŸ“Š Set X, y: Independent (TV) and Dependent (sales) variables
     â†“
âœ‚ï¸ Split Data: 70% train, 30% test
     â†“
ğŸ¤– Train Model: LinearRegression().fit()
     â†“
ğŸ¯ Make Predictions: y_pred_slr on test set
     â†“
ğŸ“ˆ Visualize: Actual vs Predicted scatter + line
     â†“
ğŸ“Š Evaluate: RÂ², MAE, MSE, RMSE metrics
```

#### ğŸ’¡ Quick Memory:

- **Real-world approach** ğŸ²
- Train/Test split prevents overfitting
- Single independent variable
- Complete model evaluation

#### ğŸ”¢ Key Variables:

- `x` â†’ TV (independent)
- `y` â†’ sales (dependent)
- `slr` â†’ LinearRegression model
- `y_pred_slr` â†’ Predictions
- Metrics: MAE, MSE, RMSE

#### ğŸ“ˆ Evaluation Metrics:

| Metric   | Purpose                      |
| -------- | ---------------------------- |
| **RÂ²**   | How well model fits (0-100%) |
| **MAE**  | Average prediction error     |
| **MSE**  | Squared average error        |
| **RMSE** | Square root of MSE           |

---

### 3ï¸âƒ£ **MultipleLinearRegression.ipynb** - Multiple Linear Regression (sklearn)

#### ğŸ¯ What it does:

Linear regression with **multiple features** (TV, radio, newspaper) using sklearn

#### ğŸ”‘ Key Steps:

```
ğŸ“¥ Load Data: Advertising.csv
     â†“
ğŸ” Select Features: TV, radio, newspaper (3 independent variables)
     â†“
ğŸ“Š Set X, y: All features vs sales
     â†“
âœ‚ï¸ Split Data: 70% train, 30% test
     â†“
ğŸ¤– Train Model: LinearRegression().fit()
     â†“
ğŸ“‹ Show Results:
   - Intercept (bâ‚€)
   - Coefficients for each feature (bâ‚, bâ‚‚, bâ‚ƒ)
     â†“
ğŸ¯ Make Predictions: y_pred_mlr on test set
     â†“
ğŸ“ˆ Visualize: Actual vs Predicted scatter + perfect fit line
     â†“
ğŸ“Š Evaluate: RÂ², MAE, MSE, RMSE metrics
```

#### ğŸ’¡ Quick Memory:

- **Advanced version** ğŸš€
- Multiple independent variables
- Shows how each feature contributes
- Better predictions than single variable
- Equation: `sales = bâ‚€ + bâ‚Ã—TV + bâ‚‚Ã—radio + bâ‚ƒÃ—newspaper`

#### ğŸ”¢ Key Variables:

- `x` â†’ TV, radio, newspaper (3 features)
- `y` â†’ sales
- `mlr` â†’ LinearRegression model
- `y_pred_mlr` â†’ Predictions
- Model shows relationship of each feature to sales

---

## ğŸ”„ Side-by-Side Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature         â”‚ Regression.ipynb â”‚ RegressionEX     â”‚ MultipleLinRegr  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Library         â”‚ scipy.stats      â”‚ sklearn          â”‚ sklearn          â”‚
â”‚ Variables       â”‚ 1                â”‚ 1 (TV)           â”‚ 3 (TV,radio,news)â”‚
â”‚ Train/Test      â”‚ âŒ No            â”‚ âœ… 70/30 split   â”‚ âœ… 70/30 split   â”‚
â”‚ Visualization   â”‚ âœ… Yes           â”‚ âœ… Yes           â”‚ âœ… Yes           â”‚
â”‚ Metrics         â”‚ r value only     â”‚ Full evaluation  â”‚ Full evaluation  â”‚
â”‚ Use Case        â”‚ Learning basics  â”‚ Real project     â”‚ Real project     â”‚
â”‚ Complexity      â”‚ â­ Beginner      â”‚ â­â­ Intermediateâ”‚ â­â­â­ Advanced   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ The Complete Workflow

### Step 1: ğŸ“¦ Import Libraries

```python
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
```

### Step 2: ğŸ“Š Load & Prepare Data

```python
dataset = pd.read_csv('Advertising.csv')
x = dataset[['TV']]  # or multiple columns
y = dataset['sales']
```

### Step 3: âœ‚ï¸ Split Data (Train/Test)

```python
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.3, random_state=100
)
```

### Step 4: ğŸ¤– Train Model

```python
model = LinearRegression()
model.fit(x_train, y_train)
```

### Step 5: ğŸ¯ Make Predictions

```python
y_pred = model.predict(x_test)
```

### Step 6: ğŸ“ˆ Visualize Results

```python
plt.scatter(x_test, y_test, label='Actual')
plt.plot(x_test, y_pred, 'red', label='Predicted')
plt.show()
```

### Step 7: ğŸ“Š Evaluate Model

```python
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = model.score(x, y) * 100
```

---

## ğŸ“Œ Quick Formulas

### ğŸ”¢ Simple Linear Regression

$$y = b_0 + b_1 \times x$$

### ğŸ”¢ Multiple Linear Regression

$$y = b_0 + b_1 \times x_1 + b_2 \times x_2 + b_3 \times x_3 + ...$$

### ğŸ“Š Evaluation Metrics

- **RÂ² Score**: $(1 - \frac{\sum(y_{actual} - y_{pred})^2}{\sum(y_{actual} - \bar{y})^2}) \times 100\%$
- **MAE**: $\frac{1}{n}\sum|y_{actual} - y_{pred}|$
- **MSE**: $\frac{1}{n}\sum(y_{actual} - y_{pred})^2$
- **RMSE**: $\sqrt{MSE}$

---

## ğŸ¯ When to Use What?

| Scenario                            | Use This                         |
| ----------------------------------- | -------------------------------- |
| ğŸ“š Learning regression basics       | `Regression.ipynb`               |
| ğŸ¢ Real project with 1 feature      | `RegressionEX.ipynb`             |
| ğŸš€ Predicting with multiple factors | `MultipleLinearRegression.ipynb` |
| ğŸ”¬ Need highest accuracy            | `MultipleLinearRegression.ipynb` |
| âš¡ Quick prototype                  | `Regression.ipynb`               |

---

## ğŸ’¾ Dataset: Advertising.csv

**Columns:**

- ğŸ“º `TV` â†’ TV advertising budget
- ğŸ“» `radio` â†’ Radio advertising budget
- ğŸ“° `newspaper` â†’ Newspaper advertising budget
- ğŸ’° `sales` â†’ Product sales (target variable)

---

## âœ… Key Takeaways

1. âœ¨ **Regression finds relationships** between input and output
2. ğŸ² **Train/Test split** prevents overfitting
3. ğŸ“ˆ **More features** can improve accuracy
4. ğŸ“Š **Evaluation metrics** tell you how good your model is
5. ğŸ”® **Predictions** allow forecasting future values

---

## ğŸš€ Quick Start

1. Open any notebook
2. Run cells from top to bottom
3. Check visualization and metrics
4. Compare results between notebooks
5. Understand progression: simple â†’ single feature â†’ multiple features

---

**Created for EL 4152 - Machine Learning | Day 07 Practicals** ğŸ“
